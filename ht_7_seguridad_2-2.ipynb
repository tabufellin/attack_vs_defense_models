{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5fc3a8b-1d2a-4aa2-b4a4-edd340afe39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adversarial-robustness-toolbox in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.17.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from adversarial-robustness-toolbox) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from adversarial-robustness-toolbox) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from adversarial-robustness-toolbox) (1.4.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from adversarial-robustness-toolbox) (65.5.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from adversarial-robustness-toolbox) (4.66.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5222188d-f794-48ae-928d-d1d0ad866269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb2681f4-f4fa-441d-aedf-3247629080cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from PIL import Image\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09db0d08-7709-4695-acc1-961730d9502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# de cuales tenemos suficiente data?\n",
    "#tenemos algunos...\n",
    "#allaple-A -!\n",
    "#yuner - a -!\n",
    "#allaple.L\n",
    "#instantaccess\n",
    "#vB.at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a45f7326-1e01-4eb5-a065-1f5d9a4a523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dontovo_a',\n",
       " 'instant_access',\n",
       " 'vb_at',\n",
       " 'dialplatform_b',\n",
       " 'adialer_c',\n",
       " 'agent_fyi',\n",
       " 'allaple_a',\n",
       " 'fakerean',\n",
       " 'yuner_a',\n",
       " 'lolyda_aa1',\n",
       " '.ipynb_checkpoints',\n",
       " 'allaple_l',\n",
       " 'auleron_gen_j']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directorio base donde se encuentran las imágenes de malware\n",
    "base_dir = './images'\n",
    "\n",
    "# Obtener la lista de familias de malware\n",
    "familias = os.listdir(base_dir)\n",
    "\n",
    "# Diccionario para almacenar las imágenes y etiquetas\n",
    "data = {\n",
    "    'imagenes': [],\n",
    "    'etiquetas': []\n",
    "}\n",
    "\n",
    "familias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dba77b49-531b-4ee7-ae90-e45c1db3415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorrer cada familia de malware\n",
    "for familia in familias:\n",
    "    familia_dir = os.path.join(base_dir, familia)\n",
    "    imagenes_familia = os.listdir(familia_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8691747-880f-40c6-af29-c87964970e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño común para redimensionar las imágenes\n",
    "target_size = (28, 28)  # Ajusta el tamaño según tus necesidades\n",
    "\n",
    "flag_counter = 0\n",
    "# Recorrer cada familia de malware\n",
    "for familia in familias:\n",
    "    familia_dir = os.path.join(base_dir, familia)\n",
    "    imagenes_familia = os.listdir(familia_dir)\n",
    "\n",
    "    \n",
    "    # Verificar si la familia tiene suficientes observaciones\n",
    "    if len(imagenes_familia) >= 10:  # Ajusta el umbral según tus necesidades\n",
    "        # Recorrer cada imagen de la familia\n",
    "\n",
    "        counter_max_check_files_of_one_family = 0\n",
    "        \n",
    "        for imagen_nombre in imagenes_familia:\n",
    "\n",
    "            ++counter_max_check_files_of_one_family\n",
    "            if (counter_max_check_files_of_one_family < 100):        \n",
    "                imagen_path = os.path.join(familia_dir, imagen_nombre)\n",
    "                \n",
    "                # Verificar si la ruta es un archivo antes de intentar abrirlo\n",
    "                if os.path.isfile(imagen_path):\n",
    "                    # Cargar la imagen y redimensionarla al tamaño común\n",
    "                    imagen = Image.open(imagen_path)\n",
    "                    imagen = imagen.resize(target_size)\n",
    "                    imagen_array = np.array(imagen)\n",
    "                    if(imagen_array.shape == (28,28)):\n",
    "            \n",
    "                    \n",
    "                        # Agregar la imagen y la etiqueta al diccionario\n",
    "                        data['imagenes'].append(imagen_array)\n",
    "                        data['etiquetas'].append(flag_counter)\n",
    "                    else:\n",
    "                        print(\"esta raro\")\n",
    "        flag_counter = flag_counter + 1\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "654167d3-3dce-4fe1-860a-387976f40bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5735 0\n"
     ]
    }
   ],
   "source": [
    "counter_si = 0\n",
    "counter_no = 0\n",
    "for imagenes in data['imagenes']:\n",
    "   \n",
    "    if (imagenes.shape == (28,28)):\n",
    "        counter_si += 1\n",
    "    else:\n",
    "        counter_no += 1\n",
    "\n",
    "print(counter_si, counter_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d0ce619-9e21-4e60-aec5-9bda375452a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las listas en arrays numpy\n",
    "X = np.array(data['imagenes'])\n",
    "y = np.array(data['etiquetas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79ebbf13-377d-4c04-9a04-4dcfc8f06b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalizar los valores de píxeles entre 0 y 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afcea5e3-d8ea-4eb5-a4f9-79278ebf5784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential([\\n    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\\n    MaxPooling2D((2, 2)),\\n    Conv2D(64, (3, 3), activation='relu'),\\n    MaxPooling2D((2, 2)),\\n    Conv2D(64, (3, 3), activation='relu'),\\n    Flatten(),\\n    Dense(64, activation='relu'),\\n    Dense(len(np.unique(y_train)), activation='softmax')\\n])\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7700110-1ed1-4e72-be90-eed380e32aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of X_train: float32\n",
      "Data type of X_test: float32\n"
     ]
    }
   ],
   "source": [
    "# Agregar la dimensión de canal a las imágenes\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "print(\"Data type of X_train:\", X_train.dtype)\n",
    "print(\"Data type of X_test:\", X_test.dtype)\n",
    "# Construir el modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92f7d987-564c-4834-aa6d-e4e8bb0549e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.4),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afdab195-4851-487b-84d8-147d448a6f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = Sequential([\\n    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(28, 28, 1)),\\n    MaxPooling2D((2, 2)),\\n    Dropout(0.3),  # Increased dropout rate\\n    \\n    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\\n    MaxPooling2D((2, 2)),\\n    Dropout(0.3),  # Increased dropout rate\\n    \\n    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),  # Added convolutional layer\\n    MaxPooling2D((2, 2)),\\n    Dropout(0.3),  # Increased dropout rate\\n    \\n    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\\n    MaxPooling2D((2, 2)),\\n    Dropout(0.3),  # Increased dropout rate\\n    \\n    Flatten(),\\n    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),  # Increased units and added regularization\\n    Dropout(0.4),  # Increased dropout rate\\n    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # Increased units and added regularization\\n    Dropout(0.4),  # Increased dropout rate\\n    Dense(len(np.unique(y_train)), activation='softmax')\\n])\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),  # Increased dropout rate\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),  # Increased dropout rate\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),  # Added convolutional layer\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),  # Increased dropout rate\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),  # Increased dropout rate\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),  # Increased units and added regularization\n",
    "    Dropout(0.4),  # Increased dropout rate\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # Increased units and added regularization\n",
    "    Dropout(0.4),  # Increased dropout rate\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c77335ba-553b-4eca-bc91-41fdfa0e763b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential([\\n    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(224, 224, 1)),\\n    MaxPooling2D((2, 2)),\\n    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\\n    MaxPooling2D((2, 2)),\\n    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\\n    Dropout(0.5),\\n    Flatten(),\\n    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\\n    Dropout(0.5),\\n    Dense(len(np.unique(y_train)), activation='softmax')\\n])\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(224, 224, 1)),  # Ajusta la forma de entrada según tus imágenes\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(224, 224, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e19df9f3-fef3-4b84-876d-fa1bea2d64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc08974e-1d3d-42ab-96ca-66c07a1ad350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4014 samples, validate on 1721 samples\n",
      "Epoch 1/5\n",
      "  32/4014 [..............................] - ETA: 10s - loss: 5.2124 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 11:18:27.921313: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-05-30 11:18:27.987200: W tensorflow/c/c_api.cc:305] Operation '{name:'training/Adam/dense_11/bias/v/Assign' id:585 op device:{requested: '', assigned: ''} def:{{{node training/Adam/dense_11/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/dense_11/bias/v, training/Adam/dense_11/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4014/4014 [==============================] - 1s 266us/sample - loss: 2.6210 - accuracy: 0.3597 - val_loss: 1.4948 - val_accuracy: 0.6903\n",
      "Epoch 2/5\n",
      "  32/4014 [..............................] - ETA: 1s - loss: 1.7475 - accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2024-05-30 11:18:28.974846: W tensorflow/c/c_api.cc:305] Operation '{name:'loss_1/AddN_1' id:375 op device:{requested: '', assigned: ''} def:{{{node loss_1/AddN_1}} = AddN[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul, loss_1/AddN)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4014/4014 [==============================] - 1s 261us/sample - loss: 1.2541 - accuracy: 0.6418 - val_loss: 0.9899 - val_accuracy: 0.7455\n",
      "Epoch 3/5\n",
      "4014/4014 [==============================] - 1s 263us/sample - loss: 0.9964 - accuracy: 0.7427 - val_loss: 0.8691 - val_accuracy: 0.8542\n",
      "Epoch 4/5\n",
      "4014/4014 [==============================] - 1s 259us/sample - loss: 0.8708 - accuracy: 0.8077 - val_loss: 0.7550 - val_accuracy: 0.9117\n",
      "Epoch 5/5\n",
      "4014/4014 [==============================] - 1s 273us/sample - loss: 0.7854 - accuracy: 0.8373 - val_loss: 0.6583 - val_accuracy: 0.9233\n",
      "Test Loss: 0.6583429577737129, Test Accuracy: 0.9233003854751587\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1dbe4f23-8dd4-4c47-8e4e-c9e2341b7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ad8a11a-133e-4dec-a205-c7e252431d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "##parte 2 -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e1e0c37-9a15-4e86-996a-e831a0370678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.utils import load_dataset\n",
    "import numpy as np\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.estimators.classification import KerasClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc34f30a-3d7d-400e-8bbf-ed81cc29fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos MNIST\n",
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_dataset('mnist')\n",
    "\n",
    "# Reduce dataset size to half\n",
    "x_train = x_train[:30000]\n",
    "y_train = y_train[:30000]\n",
    "x_test = x_test[:5000]\n",
    "y_test = y_test[:5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea2e820c-cb61-42e9-a88a-95362c131ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 28, 28, 1), (30000, 10), (5000, 28, 28, 1), (5000, 10), 0.0, 1.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, min_pixel_value, max_pixel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ae60aaf-b429-476a-b6f8-4287a1161a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape de las imágenes de entrada\n",
    "x_train = np.array([img.reshape((28, 28, 1)) for img in x_train])\n",
    "x_test = np.array([img.reshape((28, 28, 1)) for img in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0a491ee-f87f-4b31-b306-9629b39308a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un modelo simple de CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "234d0a0a-1718-41fb-9b80-01a7ecbf86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e2c768c-1958-42b2-8bed-04c23c134a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1721, 28, 28, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53f8be4b-baee-4794-acc7-22685401d202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6af9ab64-8bbc-4be8-baf7-179acc6492f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04c76766-849b-4b4b-9d09-90771fdcfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir etiquetas one-hot a escalares\n",
    "# Assuming y_train and y_test are your one-hot encoded labels\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ba71f18-21b1-49f6-a25e-25abd271fcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "# Assuming your input array is named 'input_array'\n",
    "# Resize X_test images from 224x224 to 28x28\n",
    "#X_test = tf.image.resize(X_test, (28, 28))\n",
    "\n",
    "# Set a reasonable number of epochs\n",
    "epochs = 3  # You can adjust this value based on your model's complexity\n",
    "\n",
    "# Increase the batch size (if your system allows)\n",
    "batch_size = 256  # Adjust this value based on your system's memory capacity\n",
    "\n",
    "# Reduce the steps per epoch, but not too much\n",
    "steps_per_epoch = len(x_train) // batch_size \n",
    "\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04fbfb86-a110-454f-af69-6accd50a7cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
      "Train on 117 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "117/117 [==============================] - 1965s 17s/step - batch: 58.0000 - size: 1.0000 - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.0608 - val_accuracy: 0.9816\n",
      "Epoch 2/3\n",
      "117/117 [==============================] - 2419s 21s/step - batch: 58.0000 - size: 1.0000 - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0747 - val_accuracy: 0.9820\n",
      "Epoch 3/3\n",
      "117/117 [==============================] - 1600s 14s/step - batch: 58.0000 - size: 1.0000 - loss: 9.7580e-04 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e359bbd0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_data=(x_test, y_test), steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "403d7c4c-ec85-4496-bb1f-9e51324fb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el estimador de ART\n",
    "estimator = KerasClassifier(model, clip_values=(min_pixel_value, max_pixel_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "138d5520-6d19-41c1-bd67-bbfcc4ff80fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2024-05-30 13:45:42.174584: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_13/Softmax' id:781 op device:{requested: '', assigned: ''} def:{{{node dense_13/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_13/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "Python(63622) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Implementar el ataque FastGradientMethod\n",
    "attack = FastGradientMethod(estimator=estimator, eps=0.2)\n",
    "x_test_adv = attack.generate(x=x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "33c82521-2f76-4200-a80c-6db90581c60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original test examples: 10.30%\n",
      "Accuracy on adversarial test examples: 9.30%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el ataque\n",
    "preds = np.argmax(estimator.predict(x_test), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test)) / y_test.shape[0]\n",
    "print(f'Accuracy on original test examples: {acc * 100:.2f}%')\n",
    "\n",
    "preds = np.argmax(estimator.predict(x_test_adv), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test)) / y_test.shape[0]\n",
    "print(f'Accuracy on adversarial test examples: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "927095ab-2e2b-42ad-be15-6d6ae4000c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.estimators.classification import KerasClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00ba1295-0b7e-45eb-9778-8d37131924a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "664e7802-8834-4d55-9d57-8f1e53853bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el estimador de ART con tu modelo\n",
    "estimator = KerasClassifier(model, clip_values=(min_pixel_value, max_pixel_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cd4a64f-bf33-4390-ba2a-b30d771d3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = X_train.reshape(X_train.shape[0], 224, 224, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d635b8f-7ae8-4fba-92ef-9deb5a695af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar el ataque de evasión (Fast Gradient Sign Method)\n",
    "evasion_attack = FastGradientMethod(estimator=estimator, eps=0.2)\n",
    "x_test_adv = evasion_attack.generate(x=X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "20d5904a-e54b-488a-b464-37533403a1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original test examples: 0.00%\n",
      "Accuracy on adversarial test examples (evasion attack): 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el ataque de evasión\n",
    "preds = np.argmax(estimator.predict(X_test), axis=1)\n",
    "acc = np.sum(preds == np.argmax(my_y_test)) / my_y_test.shape[0]\n",
    "print(f'Accuracy on original test examples: {acc * 100:.2f}%')\n",
    "\n",
    "preds = np.argmax(estimator.predict(x_test_adv), axis=1)\n",
    "acc = np.sum(preds == np.argmax(my_y_test)) / my_y_test.shape[0]\n",
    "print(f'Accuracy on adversarial test examples (evasion attack): {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e285d-d6aa-482d-8f1f-27777634ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFENSA DEL PRIMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f498eb58-33bf-48bf-a397-f26d0b996214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fb478516234d8a82cd5c2fe28b7c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precompute adv samples:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9e8d19daa64b66848f6d692dfc5dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adversarial training epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original test examples: 0.00%\n",
      "Accuracy on adversarial test examples (evasion attack): 0.00%\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "\n",
    "# Crear el estimador de ART con tu modelo\n",
    "estimator = KerasClassifier(model, clip_values=(min_pixel_value, max_pixel_value))\n",
    "\n",
    "# Configurar el ataque de evasión (Fast Gradient Sign Method)\n",
    "evasion_attack = attack\n",
    "\n",
    "# Configurar el entrenador adversario\n",
    "adv_trainer = AdversarialTrainer(estimator, attacks=evasion_attack)\n",
    "\n",
    "# Entrenar el modelo de forma adversaria\n",
    "mitigated_model = adv_trainer.fit(x_train, y_train, nb_epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluar el modelo adversariamente entrenado\n",
    "preds = np.argmax(estimator.predict(x_test), axis=0)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=0)) / y_test.shape[0]\n",
    "print(f'Accuracy on original test examples: {acc * 100:.2f}%')\n",
    "\n",
    "x_test_adv = evasion_attack.generate(x=x_test)\n",
    "preds = np.argmax(estimator.predict(x_test_adv), axis=0)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=0)) / y_test.shape[0]\n",
    "print(f'Accuracy on adversarial test examples (evasion attack): {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bea5dc-daf8-4e10-bc80-7d5f76b9b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTO YA VA PARA EL SEGUNDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "620c6b98-b5de-4d4b-8bd1-7511e1646cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el patrón de la puerta trasera (backdoor)\n",
    "backdoor_pattern = np.zeros((28, 28, 1))\n",
    "backdoor_pattern[0:5, 0:5, :] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8589bf1f-7402-4fbe-bcd0-d955060eef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 4s 143us/sample - loss: 7.3414e-05 - accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 4s 141us/sample - loss: 6.3971e-05 - accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 4s 128us/sample - loss: 5.7457e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd\n",
    "\n",
    "# Create the ART estimator with your model\n",
    "estimator = KerasClassifier(model, clip_values=(min_pixel_value, max_pixel_value))\n",
    "\n",
    "# Create the backdoor poisoning attack\n",
    "backdoor_attack = PoisoningAttackBackdoor(add_pattern_bd)\n",
    "\n",
    "# Generate poisoned samples\n",
    "poisoned_samples, poisoned_labels = backdoor_attack.poison(x_train, y_train)\n",
    "\n",
    "# Train a poisoned model\n",
    "poisoned_model = model.fit(poisoned_samples, poisoned_labels, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3898b238-d684-41be-b075-52cd21a1e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el estimador de ART\n",
    "estimator = KerasClassifier(model, clip_values=(min_pixel_value, max_pixel_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "469c9e64-3754-432e-8616-de9f94c465e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original test examples: 10.30%\n",
      "Accuracy on adversarial test examples: 0.02%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el ataque\n",
    "preds = np.argmax(estimator.predict(x_test), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test)) / y_test.shape[0]\n",
    "print(f'Accuracy on original test examples: {acc * 100:.2f}%')\n",
    "\n",
    "preds = np.argmax(estimator.predict(x_test_adv), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test)) / y_test.shape[0]\n",
    "print(f'Accuracy on adversarial test examples: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4c548bb6-2979-4b8d-b850-e81419576c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28, 1)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3ece3af0-7da7-4542-9bc9-f32288d704d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok ahora la cosa es defender estos modelos.\n",
    "from art.defences.detector.poison import ActivationDefence\n",
    "\n",
    "# Assuming you have the original model and the poisoned model\n",
    "\n",
    "# Create a defense object\n",
    "defense = ActivationDefence(estimator, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5da2008b-4665-4808-8f42-be3eb3d4cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_clean = defense.detect_poison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1c0b4e48-5f03-42fe-a1aa-b54f09389737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is not poisoned.\n"
     ]
    }
   ],
   "source": [
    "# Print the defense evaluation result\n",
    "if is_clean:\n",
    "    print(\"The model is not poisoned.\")\n",
    "else:\n",
    "    print(\"The model is poisoned.\")\n",
    "\n",
    "#for purpose lets always assume its poisoned\n",
    "is_clean = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a0a06dda-7444-4f26-b9eb-74ddd5016ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_indices = defense.detect_poison()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6c781411-8a35-4bfc-886d-fcb8a6164ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cluster_analysis': 'smaller',\n",
       "  'suspicious_clusters': 10,\n",
       "  'Class_0': {'cluster_0': {'ptc_data_in_cluster': 0.5,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.5, 'suspicious_cluster': False}},\n",
       "  'Class_1': {'cluster_0': {'ptc_data_in_cluster': 0.47,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.53, 'suspicious_cluster': False}},\n",
       "  'Class_2': {'cluster_0': {'ptc_data_in_cluster': 0.51,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.49, 'suspicious_cluster': True}},\n",
       "  'Class_3': {'cluster_0': {'ptc_data_in_cluster': 0.55,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.45, 'suspicious_cluster': True}},\n",
       "  'Class_4': {'cluster_0': {'ptc_data_in_cluster': 0.6,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.4, 'suspicious_cluster': True}},\n",
       "  'Class_5': {'cluster_0': {'ptc_data_in_cluster': 0.46,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.54, 'suspicious_cluster': False}},\n",
       "  'Class_6': {'cluster_0': {'ptc_data_in_cluster': 0.45,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.55, 'suspicious_cluster': False}},\n",
       "  'Class_7': {'cluster_0': {'ptc_data_in_cluster': 0.57,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.43, 'suspicious_cluster': True}},\n",
       "  'Class_8': {'cluster_0': {'ptc_data_in_cluster': 0.51,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.49, 'suspicious_cluster': True}},\n",
       "  'Class_9': {'cluster_0': {'ptc_data_in_cluster': 0.34,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.66, 'suspicious_cluster': False}},\n",
       "  'nb_clusters': 2,\n",
       "  'clustering_method': 'KMeans',\n",
       "  'nb_dims': 10,\n",
       "  'reduce': 'PCA',\n",
       "  'generator': None,\n",
       "  'ex_re_threshold': None},\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  ...])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisoned_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ff525af3-23df-49b3-9121-e1f9e79f2fa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the tuple to a list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m poisoned_indices_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpoisoned_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# Convert the tuple to a list\n",
    "poisoned_indices_list = list(poisoned_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f6e354fe-a9bb-4110-aa42-0db37479e2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cluster_analysis': 'smaller',\n",
       "  'suspicious_clusters': 10,\n",
       "  'Class_0': {'cluster_0': {'ptc_data_in_cluster': 0.5,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.5, 'suspicious_cluster': True}},\n",
       "  'Class_1': {'cluster_0': {'ptc_data_in_cluster': 0.52,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.48, 'suspicious_cluster': True}},\n",
       "  'Class_2': {'cluster_0': {'ptc_data_in_cluster': 0.51,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.49, 'suspicious_cluster': True}},\n",
       "  'Class_3': {'cluster_0': {'ptc_data_in_cluster': 0.45,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.55, 'suspicious_cluster': False}},\n",
       "  'Class_4': {'cluster_0': {'ptc_data_in_cluster': 0.6,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.4, 'suspicious_cluster': True}},\n",
       "  'Class_5': {'cluster_0': {'ptc_data_in_cluster': 0.46,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.54, 'suspicious_cluster': False}},\n",
       "  'Class_6': {'cluster_0': {'ptc_data_in_cluster': 0.45,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.55, 'suspicious_cluster': False}},\n",
       "  'Class_7': {'cluster_0': {'ptc_data_in_cluster': 0.43,\n",
       "    'suspicious_cluster': True},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.57, 'suspicious_cluster': False}},\n",
       "  'Class_8': {'cluster_0': {'ptc_data_in_cluster': 0.5,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.5, 'suspicious_cluster': True}},\n",
       "  'Class_9': {'cluster_0': {'ptc_data_in_cluster': 0.65,\n",
       "    'suspicious_cluster': False},\n",
       "   'cluster_1': {'ptc_data_in_cluster': 0.35, 'suspicious_cluster': True}},\n",
       "  'nb_clusters': 2,\n",
       "  'clustering_method': 'KMeans',\n",
       "  'nb_dims': 10,\n",
       "  'reduce': 'PCA',\n",
       "  'generator': None,\n",
       "  'ex_re_threshold': None},\n",
       " [0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  ...]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisoned_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "109c5a74-8a4a-4643-8ac2-61366565a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = poisoned_indices_list [0]\n",
    "list = poisoned_indices_list [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a304d675-9d95-44bf-b29d-a6d805b6d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the boolean values from the dictionary in the tuple\n",
    "suspicious_clusters = dict\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "suspicious_clusters_array = np.array(suspicious_clusters)\n",
    "\n",
    "# Create the non-poisoned mask\n",
    "non_poisoned_mask = np.logical_not(suspicious_clusters_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9e92d5fa-93fa-436b-9e02-b8a96a849196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 30000, 28, 28, 1), dtype=float64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "593811a8-1f47-473b-a299-42db532f449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the poisoned samples from the training set using boolean indexing\n",
    "filtered_x_train = x_train[non_poisoned_mask]\n",
    "filtered_y_train = y_train[non_poisoned_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "68f6b13f-aca5-4177-ace1-05b8881e23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_x_train = filtered_x_train.squeeze(axis=0)\n",
    "filtered_y_train = filtered_y_train.squeeze(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "90787ae6-1145-4fcb-a61f-ed4cd59cc3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 28, 28, 1)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0753b666-99b0-49a0-9ec5-6b233457f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 4s 139us/sample - loss: 6.5705e-04 - accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 4s 128us/sample - loss: 5.2228e-04 - accuracy: 0.9999\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 4s 124us/sample - loss: 3.6847e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a new model on the filtered data\n",
    "mitigated_model = model.fit(filtered_x_train, filtered_y_train, epochs=epochs, batch_size=batch_size)\n",
    "# Evaluar la defense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e8c44-64e6-4365-81cf-b8626781e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ART estimator\n",
    "estimator = KerasClassifier(mitigated_model, clip_values=(min_pixel_value, max_pixel_value))\n",
    "\n",
    "\n",
    "# Evaluate the model on the original test data\n",
    "preds = np.argmax(estimator.predict(X_test), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(f'Accuracy on original test examples: {acc * 100:.2f}%')\n",
    "\n",
    "# Generate adversarial test examples\n",
    "X_test_adv = evasion_attack.generate(x=X_test)\n",
    "\n",
    "# Evaluate the model on the adversarial test examples\n",
    "preds = np.argmax(estimator.predict(X_test), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(f'Accuracy on adversarial test examples (evasion attack): {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a7c9c-f048-40ca-a73c-138129c96931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
